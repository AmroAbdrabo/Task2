{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt, fabs, exp\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.linear_model import enet_path\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dfX = pd.read_csv(\"X_train.csv\")\n",
    "dfTest = pd.read_csv(\"X_test.csv\")\n",
    "dfY = pd.read_csv(\"y_train.csv\")\n",
    "XPred = dfTest.iloc[:, 1:].values\n",
    "X = dfX.iloc[:, 1:].values\n",
    "y = dfY.iloc[:, 1:].values\n",
    "\n",
    "#Check there are no nans\n",
    "print((X == np.nan).astype(int).sum()) \n",
    "print((y == np.nan).astype(int).sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing 30% test sample may not preserve population proportions\n",
    "\n",
    "___\n",
    "\n",
    "##### Solution is to sample each population of a specific label independently #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified sampling by labels\n",
    "nrows = len(X)\n",
    "classes = [1, 2]\n",
    "\n",
    "# sample only the zero-labeled points (then sample the remaning data points in the next for loop)\n",
    "xTemp = [X[i] for i in range(nrows) if y[i] == 0]\n",
    "yTemp = [y[i] for i in range(nrows) if y[i] == 0]\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xTemp, yTemp, test_size=0.30, random_state=531)\n",
    "\n",
    "# append the other data points from the other classes\n",
    "for iLabel in classes:\n",
    "    xTemp = [X[i] for i in range(nrows) if y[i] == iLabel]\n",
    "    yTemp = [y[i] for i in range(nrows) if y[i] == iLabel]\n",
    "    \n",
    "    #form train and test sets on segregated subset of examples    \n",
    "    xTrainTemp, xTestTemp, yTrainTemp, yTestTemp = train_test_split(xTemp, yTemp, test_size=0.30, random_state=531) \n",
    "    \n",
    "    #accumulate    \n",
    "    xTrain = numpy.append(xTrain, xTrainTemp, axis=0)    \n",
    "    xTest = numpy.append(xTest, xTestTemp, axis=0)    \n",
    "    yTrain = numpy.append(yTrain, yTrainTemp, axis=0)    \n",
    "    yTest = numpy.append(yTest, yTestTemp, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for optimal hyperparameters for GBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTreeList = np.arange(50, 1700, 35)\n",
    "max_feats = np.arange(3, 800, 25)\n",
    "depths = np.arange(2, 11, 1)\n",
    "learnRate = 0.05\n",
    "subSamp = 1\n",
    "search_model_params = GridSearchCV(\n",
    "    ensemble.GradientBoostingClassifier(learning_rate=learnRate, subsample=subSamp),{\n",
    "    'n_estimators': nTreeList,\n",
    "    'max_depth':depths,\n",
    "    'max_features': max_feats   \n",
    "    }, cv=5, return_train_score = False\n",
    ")\n",
    "search_model_params.fit(X, y)\n",
    "print(search_model_params.best_params_)\n",
    "print(search_model_params.best_score_)\n",
    "predictions = search_model_params.predict(XPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPredictions = pd.DataFrame(predictions)\n",
    "dfPredictions.index.name = \"id\"\n",
    "df.to_csv(\"gboostedtask2noimbalance.csv\", header = ['y'], index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
